{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee18c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\anaconda\\lib\\site-packages (from opencv-python) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "# Installing necessary Packages\n",
    "\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37c414e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.3)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.53.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in d:\\anaconda\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.9.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anaconda\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af394be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ae0ce",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af90c993-03cc-44a7-b6ba-adeeae8d2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define the path to the zip file\n",
    "zip_file_path = \"archive.zip\"  # Update this with the actual zip file name\n",
    "extract_path = \"Biometrics/CASIA_B_extracted\"  # Folder where extracted files will be stored\n",
    "\n",
    "# Create the extraction folder if it doesn't exist\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Extraction completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c74aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Biometrics/CASIA_B_extracted/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ad254c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Setting the seed for reproducibility\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def split_dataset(dataset_path, output_path, train_ratio=0.7, val_ratio=0.15):\n",
    "    \n",
    "    # Create train, validation, and test directories\n",
    "    \n",
    "    train_dir = os.path.join(output_path, 'train')\n",
    "    \n",
    "    val_dir = os.path.join(output_path, 'validation')\n",
    "    \n",
    "    test_dir = os.path.join(output_path, 'test')\n",
    "\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    \n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    \n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Iterating through all the subject folders\n",
    "    \n",
    "    for subject_id in range(1, 125):\n",
    "        \n",
    "        subject_folder = os.path.join(dataset_path, f'{subject_id:03d}')\n",
    "        \n",
    "        subject_images = []\n",
    "\n",
    "        # Gathering all images for the current subject\n",
    "        \n",
    "        for root, _, files in os.walk(subject_folder):\n",
    "            \n",
    "            for file in files:\n",
    "                \n",
    "                if file.endswith('.png') or file.endswith('.jpg'):\n",
    "                    \n",
    "                    subject_images.append(os.path.join(root, file))\n",
    "\n",
    "        # Shuffling the images\n",
    "        \n",
    "        random.shuffle(subject_images)\n",
    "\n",
    "        # Calculating the number of images for each partition\n",
    "        \n",
    "        total_images = len(subject_images)\n",
    "        \n",
    "        train_count = int(total_images * train_ratio)\n",
    "        \n",
    "        val_count = int(total_images * val_ratio)\n",
    "        \n",
    "        test_count = total_images - train_count - val_count\n",
    "\n",
    "        # Spliting the images into train, validation, and test sets\n",
    "        \n",
    "        train_images = subject_images[:train_count]\n",
    "        \n",
    "        val_images = subject_images[train_count:train_count + val_count]\n",
    "        \n",
    "        test_images = subject_images[train_count + val_count:]\n",
    "\n",
    "        # Copying the images to their respective directories\n",
    "        \n",
    "        for partition, images in zip(['train', 'validation', 'test'], [train_images, val_images, test_images]):\n",
    "            \n",
    "            partition_dir = os.path.join(output_path, partition, f'{subject_id:03d}')\n",
    "            \n",
    "            os.makedirs(partition_dir, exist_ok=True)\n",
    "\n",
    "            for image_path in images:\n",
    "                \n",
    "                shutil.copy(image_path, os.path.join(partition_dir, Path(image_path).name))\n",
    "\n",
    "# Setting the path to the original dataset and the output directory\n",
    "\n",
    "dataset_path = \"Biometrics/CASIA_B_extracted/output\"\n",
    "\n",
    "output_path = \"Biometrics/CASIA_B_Split\"\n",
    "\n",
    "# Spliting the dataset\n",
    "\n",
    "split_dataset(dataset_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e080495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 782803 images belonging to 124 classes.\n",
      "Found 167694 images belonging to 124 classes.\n",
      "Found 167876 images belonging to 124 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Setting the path to the output directory\n",
    "\n",
    "output_path = \"Biometrics/CASIA_B_Split\"\n",
    "\n",
    "# Defining the output image size\n",
    "\n",
    "output_image_size = (224, 224)\n",
    "\n",
    "def grayscale_to_rgb_preprocessing(x):\n",
    "    \n",
    "    x = np.stack([x[..., 0], x[..., 0], x[..., 0]], axis=-1)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "data_gen = ImageDataGenerator(preprocessing_function=grayscale_to_rgb_preprocessing,\n",
    "                              \n",
    "                              rescale=1./255,\n",
    "                              \n",
    "                              rotation_range=15,\n",
    "                              \n",
    "                              width_shift_range=0.1,\n",
    "                              \n",
    "                              height_shift_range=0.1,\n",
    "                              \n",
    "                              horizontal_flip=True)\n",
    "\n",
    "# Defining the ImageDataGenerator for validation and test sets (no augmentation)\n",
    "\n",
    "validation_data_gen = ImageDataGenerator(preprocessing_function=grayscale_to_rgb_preprocessing, rescale=1./255)\n",
    "\n",
    "# Creating iterators for the train, validation, and test sets\n",
    "\n",
    "train_iterator = data_gen.flow_from_directory(os.path.join(output_path, 'train'),\n",
    "                                              \n",
    "                                              target_size=output_image_size,\n",
    "                                              \n",
    "                                              color_mode='rgb',\n",
    "                                              \n",
    "                                              batch_size=32,\n",
    "                                              \n",
    "                                              class_mode='categorical')\n",
    "\n",
    "validation_iterator = validation_data_gen.flow_from_directory(os.path.join(output_path, 'validation'),\n",
    "                                                              \n",
    "                                                              target_size=output_image_size,\n",
    "                                                              \n",
    "                                                              color_mode='rgb',\n",
    "                                                              \n",
    "                                                              batch_size=32,\n",
    "                                                              \n",
    "                                                              class_mode='categorical')\n",
    "\n",
    "test_iterator = validation_data_gen.flow_from_directory(os.path.join(output_path, 'test'),\n",
    "                                                        \n",
    "                                                        target_size=output_image_size,\n",
    "                                                        \n",
    "                                                        color_mode='rgb',\n",
    "                                                        \n",
    "                                                        batch_size=32,\n",
    "                                                        \n",
    "                                                        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7400182",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_size = train_iterator.n\n",
    "\n",
    "validation_dataset_size = validation_iterator.n\n",
    "\n",
    "test_dataset_size = test_iterator.n\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "#Reduced batch size to speed up the training process.\n",
    "\n",
    "train_steps_per_epoch = int(np.ceil(train_dataset_size / batch_size))\n",
    "\n",
    "validation_steps_per_epoch = int(np.ceil(validation_dataset_size / batch_size))\n",
    "\n",
    "test_steps_per_epoch = int(np.ceil(test_dataset_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f787b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs_and_labels(data_iterator, steps_per_epoch):\n",
    "    \n",
    "    for _ in range(steps_per_epoch):\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # Getting the next batch of images and labels\n",
    "            \n",
    "            images, labels = next(data_iterator)\n",
    "            \n",
    "        except StopIteration:\n",
    "            \n",
    "            # If the iterator reaches the end of the dataset, reset the iterator and continue\n",
    "            \n",
    "            data_iterator.reset()\n",
    "            \n",
    "            images, labels = next(data_iterator)\n",
    "\n",
    "        # Calculating the number of pairs\n",
    "        \n",
    "        num_pairs = images.shape[0] * 2\n",
    "\n",
    "        # Creating an empty array for the image pairs and labels\n",
    "        \n",
    "        image_pairs = np.zeros((num_pairs, 2, images.shape[1], images.shape[2], images.shape[3]))\n",
    "        \n",
    "        pair_labels = np.zeros((num_pairs,))\n",
    "\n",
    "        for i in range(0, num_pairs, 2):\n",
    "            \n",
    "            idx1 = i // 2\n",
    "\n",
    "            # Positive pair\n",
    "            \n",
    "            image_pairs[i, 0] = images[idx1]\n",
    "            \n",
    "            image_pairs[i, 1] = images[idx1]\n",
    "            \n",
    "            pair_labels[i] = 1\n",
    "\n",
    "            # Negative pair\n",
    "            \n",
    "            idx2_candidates = np.where(labels != labels[idx1])[0]\n",
    "            \n",
    "            idx2 = np.random.choice(idx2_candidates)\n",
    "            \n",
    "            image_pairs[i + 1, 0] = images[idx1]\n",
    "            \n",
    "            image_pairs[i + 1, 1] = images[idx2]\n",
    "            \n",
    "            pair_labels[i + 1] = 0\n",
    "\n",
    "        yield [image_pairs[:, 0], image_pairs[:, 1]], pair_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d32e3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create iterators for the train, validation, and test sets that generate image pairs and their labels\n",
    "\n",
    "train_pair_iterator = create_pairs_and_labels(train_iterator, train_steps_per_epoch)\n",
    "\n",
    "validation_pair_iterator = create_pairs_and_labels(validation_iterator, validation_steps_per_epoch)\n",
    "\n",
    "test_pair_iterator = create_pairs_and_labels(test_iterator, test_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bde2b6f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Loading the pre-trained MobileNetV2 model without the top classification layer\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "#Using MobileNetV2 model with pre-trained weights. \n",
    "\n",
    "#This is a good strategy to speed up the training, as the model has already learned useful features from a large dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a6e25f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed left shape: (None, 7, 7, 1280)\n",
      "Processed right shape: (None, 7, 7, 1280)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Lambda, Subtract\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_siamese_model(base_model):\n",
    "    \n",
    "    # Defining the input tensors for the two input images\n",
    "    \n",
    "    input_left = Input(shape=(224, 224, 3))\n",
    "    \n",
    "    input_right = Input(shape=(224, 224, 3))\n",
    "\n",
    "    # Processing both input images using the same base model\n",
    "    \n",
    "    processed_left = base_model(input_left)\n",
    "    \n",
    "    processed_right = base_model(input_right)\n",
    "    \n",
    "    print(\"Processed left shape:\", processed_left.shape) \n",
    "    \n",
    "    print(\"Processed right shape:\", processed_right.shape) \n",
    "\n",
    "    # Flattening the feature vectors\n",
    "    \n",
    "    flat_left = Flatten()(processed_left)\n",
    "    \n",
    "    flat_right = Flatten()(processed_right)\n",
    "\n",
    "    # Computing the L1 distance between the two feature vectors\n",
    "    \n",
    "    distance = Lambda(lambda x: tf.abs(x[0] - x[1]))([flat_left, flat_right])\n",
    "\n",
    "    # Adding a dense layer to learn the embeddings\n",
    "    \n",
    "    embeddings = Dense(128, activation='relu')(distance)\n",
    "\n",
    "    # Adding the final output layer\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(embeddings)\n",
    "\n",
    "    # Creating the Siamese model\n",
    "    \n",
    "    siamese_model = Model(inputs=[input_left, input_right], outputs=output)\n",
    "\n",
    "    return siamese_model\n",
    "\n",
    "# Create the Siamese network with the pre-trained MobileNetV2 model\n",
    "siamese_model = create_siamese_model(base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06c5e905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24463/24463 [==============================] - 269246s 11s/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 3.2063e-04 - val_accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# Determining the number of training and validation steps per epoch\n",
    "\n",
    "train_steps_per_epoch = len(train_iterator)\n",
    "\n",
    "validation_steps = len(validation_iterator)\n",
    "\n",
    "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the Siamese network using the pair iterators\n",
    "\n",
    "history = siamese_model.fit(train_pair_iterator,\n",
    "                            \n",
    "                            validation_data=validation_pair_iterator,\n",
    "                            \n",
    "                            steps_per_epoch=train_steps_per_epoch,\n",
    "                            \n",
    "                            validation_steps=validation_steps,\n",
    "                            \n",
    "                            batch_size=32,\n",
    "                            \n",
    "                            epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e776add5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5247/5247 [==============================] - 10152s 2s/step - loss: 4.3947e-04 - accuracy: 0.9999\n",
      "Test loss: 0.0004394710995256901\n",
      "Test accuracy: 0.9998868107795715\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = siamese_model.evaluate(test_pair_iterator, steps=test_steps_per_epoch)\n",
    "\n",
    "print(\"Test loss:\", test_loss)\n",
    "\n",
    "print(\"Test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2aea3ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "siamese_model.save('siamese_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68d86dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5247/5247 [==============================] - 9854s 2s/step\n"
     ]
    }
   ],
   "source": [
    "test_pair_iterator = create_pairs_and_labels(test_iterator, test_steps_per_epoch)\n",
    "\n",
    "y_pred = siamese_model.predict(test_pair_iterator, steps=test_steps_per_epoch)\n",
    "\n",
    "y_pred_labels = np.where(y_pred > 0.5, 1, 0)  # Converting probabilities to binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ff45f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pair_iterator = create_pairs_and_labels(test_iterator, test_steps_per_epoch)\n",
    "\n",
    "y_true_labels = []\n",
    "\n",
    "for i in range(test_steps_per_epoch):\n",
    "    \n",
    "    _, labels_batch = next(test_pair_iterator)\n",
    "    \n",
    "    y_true_labels.extend(labels_batch)\n",
    "    \n",
    "y_true_labels = np.array(y_true_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dbedf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9997558317502099\n",
      "Recall: 1.0\n",
      "F1-score: 0.9998779009687515\n",
      "AUC-ROC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true_labels, y_pred_labels, average='binary')\n",
    "\n",
    "auc_roc = roc_auc_score(y_true_labels, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "print(f\"F1-score: {f1_score}\")\n",
    "\n",
    "print(f\"AUC-ROC: {auc_roc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a57dcb73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Values\n",
      "Test loss      0.000439\n",
      "Test accuracy  0.999887\n",
      "Precision      0.999756\n",
      "Recall         1.000000\n",
      "F1-score       0.999878\n",
      "AUC-ROC        1.000000\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Metrics to plot\n",
    "\n",
    "metrics = ['Test loss', 'Test accuracy', 'Precision', 'Recall', 'F1-score', 'AUC-ROC']\n",
    "\n",
    "values = [test_loss, test_accuracy, precision, recall, f1_score, auc_roc]\n",
    "\n",
    "# Create a bar plot\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(metrics, values)\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "\n",
    "plt.ylabel('Values')\n",
    "\n",
    "plt.title('Model Performance Metrics')\n",
    "\n",
    "plt.ylim([0, 1.1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Creating a table using pandas\n",
    "\n",
    "results_df = pd.DataFrame(values, index=metrics, columns=['Values'])\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e5041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
